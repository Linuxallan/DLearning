{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrón Multicapa: Caso práctico II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de datos del MNIST (base de datos modificada del Instituto Nacional de Normas y Tecnología) es una gran base de datos de dígitos manuscritos que se utiliza comúnmente para la capacitación de diversos sistemas de procesamiento de imágenes. La base de datos también se utiliza ampliamente para la capacitación y el ensayo en el campo del aprendizaje automático. Se creó \"remezclando\" las muestras de los conjuntos de datos originales del NIST. Los creadores consideraron que, dado que el conjunto de datos de capacitación del NIST fue tomado de los empleados de la Oficina del Censo de los Estados Unidos, mientras que el conjunto de datos de prueba fue tomado de los estudiantes de secundaria de los Estados Unidos, no era muy adecuado para los experimentos de aprendizaje automático. Además, las imágenes en blanco y negro del NIST fueron normalizadas para que encajaran en un cuadro delimitador de 28x28 píxeles, lo que introdujo niveles de escala de grises.\n",
    "\n",
    "La base de datos del MNIST contiene 60.000 imágenes de entrenamiento y 10.000 imágenes de prueba. La mitad del conjunto de entrenamiento y la otra mitad del conjunto de pruebas se tomaron del conjunto de datos de entrenamiento del NIST, mientras que la otra mitad del conjunto de entrenamiento y la otra mitad del conjunto de pruebas se tomaron del conjunto de datos de pruebas del NIST.Los creadores originales de la base de datos mantienen una lista de algunos de los métodos probados en ella. En su papel original, utilizan una máquina de soporte vectorial para obtener una tasa de error del 0,8%. En 2017 se ha publicado un conjunto de datos ampliado similar al MNIST llamado EMNIST, que contiene 240.000 imágenes de entrenamiento y 40.000 imágenes de prueba de dígitos y caracteres escritos a mano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enunciado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso de uso práctico vamos a recuperar el ejercicio de clasificación de imágenes que realizamos en el apartado anterior para intentar mejorarlo aplicando un Perceptrón Multicapa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lectura del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el conjunto de datos\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "1          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "2          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "3          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "4          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0           0.0       0.0       0.0       0.0       0.0  \n",
       "1           0.0       0.0       0.0       0.0       0.0  \n",
       "2           0.0       0.0       0.0       0.0       0.0  \n",
       "3           0.0       0.0       0.0       0.0       0.0  \n",
       "4           0.0       0.0       0.0       0.0       0.0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "69995       0.0       0.0       0.0       0.0       0.0  \n",
       "69996       0.0       0.0       0.0       0.0       0.0  \n",
       "69997       0.0       0.0       0.0       0.0       0.0  \n",
       "69998       0.0       0.0       0.0       0.0       0.0  \n",
       "69999       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[70000 rows x 784 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conviertiendo el conjunto de datos en un DataFrame de Pandas\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(mnist.data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualización del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1 into shape (28,28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/allancortez/Documents/DLearning/DLearning/Sec 5 Error and Optimization Functions/Image Classification with Multi Layer Perceptron.ipynb Celda 10\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/allancortez/Documents/DLearning/DLearning/Sec%205%20Error%20and%20Optimization%20Functions/Image%20Classification%20with%20Multi%20Layer%20Perceptron.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, digit \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m6\u001b[39m), mnist\u001b[39m.\u001b[39mdata[:\u001b[39m5\u001b[39m]):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/allancortez/Documents/DLearning/DLearning/Sec%205%20Error%20and%20Optimization%20Functions/Image%20Classification%20with%20Multi%20Layer%20Perceptron.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     plt\u001b[39m.\u001b[39msubplot(\u001b[39m1\u001b[39m, \u001b[39m6\u001b[39m, index)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/allancortez/Documents/DLearning/DLearning/Sec%205%20Error%20and%20Optimization%20Functions/Image%20Classification%20with%20Multi%20Layer%20Perceptron.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     plt\u001b[39m.\u001b[39mimshow(np\u001b[39m.\u001b[39;49mreshape(digit, (\u001b[39m28\u001b[39;49m,\u001b[39m28\u001b[39;49m)), cmap\u001b[39m=\u001b[39mplt\u001b[39m.\u001b[39mcm\u001b[39m.\u001b[39mgray)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/allancortez/Documents/DLearning/DLearning/Sec%205%20Error%20and%20Optimization%20Functions/Image%20Classification%20with%20Multi%20Layer%20Perceptron.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mEjemplo: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(index))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/allancortez/Documents/DLearning/DLearning/Sec%205%20Error%20and%20Optimization%20Functions/Image%20Classification%20with%20Multi%20Layer%20Perceptron.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/Users/anaconda3/envs/deepl/lib/python3.8/site-packages/numpy/core/fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(a, newshape, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    200\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mreshape\u001b[39;49m\u001b[39m'\u001b[39;49m, newshape, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[0;32m/Users/anaconda3/envs/deepl/lib/python3.8/site-packages/numpy/core/fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m bound \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, method, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m bound \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/Users/anaconda3/envs/deepl/lib/python3.8/site-packages/numpy/core/fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     wrap \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(asarray(obj), method)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m wrap:\n\u001b[1;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, mu\u001b[39m.\u001b[39mndarray):\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (28,28)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for index, digit in zip(range(1, 6), mnist.data[:5]):\n",
    "    plt.subplot(1, 5, index)\n",
    "    plt.imshow(np.reshape(digit, (28,28)), cmap=plt.cm.gray)\n",
    "    plt.title('Ejemplo: ' + str(index))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. División del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59500\n",
      "10500\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento del algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(10,), solver=&#x27;sgd&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(10,), solver=&#x27;sgd&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(10,), solver='sgd')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic', solver='sgd')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de capas del perceptrón multicapa\n",
    "clf.n_layers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de outputs del perceptrón multicapa\n",
    "clf.n_outputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7850"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numero de parametros de la Hidden Layer\n",
    "784 * 10 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de parámetros que forman el modelo\n",
    "clf.coefs_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.37212029,  0.96712836, -1.6847656 , -1.45873354,  1.46780109,\n",
       "        -1.39506224, -1.72039312,  0.76217727,  1.76475886,  0.8602608 ],\n",
       "       [ 1.09362723, -1.57819808, -0.46041983, -1.6833539 , -0.55068003,\n",
       "         2.01282164,  1.24561637,  1.00135039,  0.80600141, -0.94561789],\n",
       "       [ 0.41128253, -2.45192947, -0.39941648,  1.86653986,  1.17072811,\n",
       "         1.11102169, -1.95969993,  1.27183215, -1.63256951,  0.9694186 ],\n",
       "       [-1.6766675 ,  2.02635197, -1.22082232, -1.28738569,  2.37908752,\n",
       "        -1.37691159,  2.50298581, -0.8868601 , -1.68288856,  1.15643138],\n",
       "       [-1.46727555, -1.81334649,  1.04380957, -1.44040669,  1.58312218,\n",
       "         0.67407015,  1.17848605, -2.40062924,  1.29730737,  1.31361963],\n",
       "       [-1.43350302,  0.76647449,  2.05801613,  0.96636845, -1.74377823,\n",
       "        -1.52582605, -1.99302017,  0.6006058 ,  1.40928207,  0.9998257 ],\n",
       "       [ 2.22831906,  0.85443305,  2.97467361, -0.86072605, -1.14923347,\n",
       "        -1.38461394,  2.04206284, -1.2396817 , -1.79170636, -1.05174266],\n",
       "       [ 1.7208441 , -0.78198094, -1.34537393,  1.49367262, -1.68963488,\n",
       "         1.3797129 ,  0.52025319, -1.99499292,  0.6007912 ,  0.41710401],\n",
       "       [-1.19275471,  1.27844639, -0.58308268, -0.67036651, -2.05095511,\n",
       "        -0.42061542, -1.19123768,  2.59414381, -0.84870143,  1.92360326],\n",
       "       [-1.93756137,  1.73721181,  0.05861854,  1.80625318, -1.12580926,\n",
       "         1.68413673,  0.30652424, -1.46861639,  1.29879654, -1.84366902]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensiones de la primera capa (hidden layer)\n",
    "clf.coefs_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensiones de la segunda capa (output layer)\n",
    "clf.coefs_[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parametros bias/intercept que forman parte de cada capa de la red neuronal\n",
    "clf.intercepts_[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predicción con el conjunto de pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la predicción con el conjunto de datos de prueba\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8843292538369122"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos el f1_score resultante de la clasificación\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volver a repetir el ejercicio pero aumentando el numero de neuronas en la hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Mostrando las imagenes mal clasificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 0\n",
    "index_errors = []\n",
    "\n",
    "for label, predict in zip(y_test, y_pred):\n",
    "    if label != predict:\n",
    "        index_errors.append(index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "95",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Users/anaconda3/envs/deepl/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/Users/anaconda3/envs/deepl/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Users/anaconda3/envs/deepl/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 95",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/allancortez/Documents/DLearning/DLearning/Sec 5 Error and Optimization Functions/Image Classification with Multi Layer Perceptron.ipynb Celda 29\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/allancortez/Documents/DLearning/DLearning/Sec%205%20Error%20and%20Optimization%20Functions/Image%20Classification%20with%20Multi%20Layer%20Perceptron.ipynb#X40sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, img_index \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m9\u001b[39m), index_errors[\u001b[39m8\u001b[39m:\u001b[39m16\u001b[39m]):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/allancortez/Documents/DLearning/DLearning/Sec%205%20Error%20and%20Optimization%20Functions/Image%20Classification%20with%20Multi%20Layer%20Perceptron.ipynb#X40sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     plt\u001b[39m.\u001b[39msubplot(\u001b[39m1\u001b[39m, \u001b[39m8\u001b[39m, i)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/allancortez/Documents/DLearning/DLearning/Sec%205%20Error%20and%20Optimization%20Functions/Image%20Classification%20with%20Multi%20Layer%20Perceptron.ipynb#X40sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     plt\u001b[39m.\u001b[39mimshow(np\u001b[39m.\u001b[39mreshape(X_test[img_index], (\u001b[39m28\u001b[39m,\u001b[39m28\u001b[39m)), cmap\u001b[39m=\u001b[39mplt\u001b[39m.\u001b[39mcm\u001b[39m.\u001b[39mgray)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/allancortez/Documents/DLearning/DLearning/Sec%205%20Error%20and%20Optimization%20Functions/Image%20Classification%20with%20Multi%20Layer%20Perceptron.ipynb#X40sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mOrig:\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(y_test[img_index]) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m Pred:\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(y_pred[img_index]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/allancortez/Documents/DLearning/DLearning/Sec%205%20Error%20and%20Optimization%20Functions/Image%20Classification%20with%20Multi%20Layer%20Perceptron.ipynb#X40sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m/Users/anaconda3/envs/deepl/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Users/anaconda3/envs/deepl/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 95"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i, img_index in zip(range(1, 9), index_errors[8:16]):\n",
    "    plt.subplot(1, 8, i)\n",
    "    plt.imshow(np.reshape(X_test[img_index], (28,28)), cmap=plt.cm.gray)\n",
    "    plt.title('Orig:' + str(y_test[img_index]) + ' Pred:' + str(y_pred[img_index]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
